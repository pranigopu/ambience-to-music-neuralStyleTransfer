{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dc0ac8f-26cd-4483-80d9-bb6323cf5b96",
   "metadata": {},
   "source": [
    "# IMPORTS FOR MODEL HANDLING\n",
    "\"Models\" here refer to models specifically for genre classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8df5dff4-e58f-47d0-bb07-7d3397a0201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For handling neural networks:\n",
    "import keras\n",
    "\n",
    "# For handling NumPy arrays:\n",
    "import numpy as np\n",
    "\n",
    "# For plotting:\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940c3e54-c090-433f-9384-3839bce244c8",
   "metadata": {},
   "source": [
    "**Some preliminary issues faced & their solutions**\n",
    "\n",
    "**ISSUE**: Dependencies for `keras`\n",
    "\n",
    "I was unable to import `keras` without having `tensorflow` installed.\n",
    "\n",
    "---\n",
    "\n",
    "**ISSUE**: Changing certain OS settings to install `tensorflow`\n",
    "\n",
    "I was unable to install `tensorflow` without referring to the following:\n",
    "\n",
    "https://learn.microsoft.com/en-us/windows/win32/fileio/maximum-file-path-limitation?tabs=powershell#enable-long-paths-in-windows-10-version-1607-and-later\n",
    "\n",
    "I followed the PowerShell solution given.\n",
    "\n",
    "---\n",
    "\n",
    "**ISSUE**: Procedure entry point not in the dynamic link library\n",
    "\n",
    "I faced the following error from the Windows OS (in a dialog box):\n",
    "\n",
    "```\n",
    "The procedure entry point could not be located in the dynamic link library <DDL path>.\n",
    "```\n",
    "\n",
    "NOTE: `<DDL path>` is a placeholder for the actual path.\n",
    "\n",
    "To solve this, I simply restarted and updated the OS. To verify the integrity of the system files, I ran:\n",
    "\n",
    "```\n",
    "sfc /scannow\n",
    "```\n",
    "\n",
    "NOTE: The above needs to be run as an administrator in Command Prompt.\n",
    "\n",
    "This solution was found here...\n",
    "\n",
    "https://www.drivereasy.com/knowledge/fixed-entry-point-not-found-error-in-windows/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e92312-229b-4918-ae02-f0b7f25bdcf2",
   "metadata": {},
   "source": [
    "# Model architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e34e90-f36e-468a-81c9-a9f3779a7197",
   "metadata": {},
   "source": [
    "## 3-second MFCCs input CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cf025e-6b8d-4c1c-a311-6088251e80c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_3_sec_mfcc(input_shape, n_classes=10, lr=0.0001): # There are 10 genres, so 10 classes\n",
    "    '''\n",
    "    Input parameters:\n",
    "    - `input_shape (tuple)`: Shape of input data\n",
    "    - `n_classes`: Number of output classes\n",
    "\n",
    "    Return values:\n",
    "    - `model`: CNN model\n",
    "    '''\n",
    "\n",
    "    # BUILD MODEL TOPOLOGY\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Input(input_shape),\n",
    "        #________________________\n",
    "        # CONVOLUTIONAL LAYERS\n",
    "        keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "\n",
    "        keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "\n",
    "        keras.layers.Conv2D(32, (2, 2), activation='relu'),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        #________________________\n",
    "        # DENSE LAYERS\n",
    "        # Flatten output and feed it into dense layer:\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        keras.layers.Dense(n_classes, activation='softmax')]) # Output layer\n",
    "    \n",
    "    #------------------------------------\n",
    "    # COMPILING MODEL WITH APPROPRIATE LOSS AND OPTIMIZER\n",
    "\n",
    "    # Optimizer:\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "    # Loss function:\n",
    "    loss = keras.losses.CategoricalCrossentropy()\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fff3130-41f9-4aa7-a91f-470bddcb90bf",
   "metadata": {},
   "source": [
    "## 5-second MFCCs input CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71e70e5-c4f4-4e5e-9c1c-1a1e6d4d0b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_5_sec_mfcc(input_shape, n_classes=10, lr=0.0001): # There are 10 genres, so 10 classes\n",
    "    '''\n",
    "    Input parameters:\n",
    "    - `input_shape (tuple)`: Shape of input data\n",
    "    - `n_classes`: Number of output classes\n",
    "\n",
    "    Return values:\n",
    "    - `model`: CNN model\n",
    "    '''\n",
    "\n",
    "    # BUILD MODEL TOPOLOGY\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Input(input_shape),\n",
    "        keras.layers.Identity(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        #________________________\n",
    "        # CONVOLUTIONAL LAYERS\n",
    "        keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same'),\n",
    "\n",
    "        keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same'),\n",
    "\n",
    "        keras.layers.Conv2D(32, (2, 2), activation='relu'),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "\n",
    "        keras.layers.Conv2D(32, (2, 2), activation='relu'),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "        \n",
    "        keras.layers.Conv2D(32, (2, 2), activation='relu'),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.3), # Previously was after 1st dense layer and was equal to 0.5\n",
    "        #________________________\n",
    "        # DENSE LAYERS\n",
    "        # Flatten output and feed it into dense layer:\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        keras.layers.Dense(n_classes, activation='softmax')]) # Output layer\n",
    "    \n",
    "    #------------------------------------\n",
    "    # COMPILING MODEL WITH APPROPRIATE LOSS AND OPTIMIZER\n",
    "\n",
    "    # Optimizer:\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "    # Loss function:\n",
    "    loss = keras.losses.CategoricalCrossentropy()\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa328612-942a-41fe-9653-a5a8b475f504",
   "metadata": {},
   "source": [
    "## 3-second segment melspectrogram input CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6866202-1a41-4faa-93ad-149cab20fe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_3_sec_melspectrogram(input_shape, n_classes=10, lr=0.0001): # There are 10 genres, so 10 classes\n",
    "    '''\n",
    "    Input parameters:\n",
    "    - `input_shape (tuple)`: Shape of input data\n",
    "    - `n_classes`: Number of output classes\n",
    "\n",
    "    Return values:\n",
    "    - `model`: CNN model\n",
    "    '''\n",
    "\n",
    "    # BUILD MODEL TOPOLOGY\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Input(input_shape),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        #________________________\n",
    "        # CONVOLUTIONAL LAYERS\n",
    "        keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same'),\n",
    "\n",
    "        keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same'),\n",
    "\n",
    "        keras.layers.Conv2D(32, (2, 2), activation='relu'),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "\n",
    "        keras.layers.Conv2D(32, (2, 2), activation='relu'),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        #________________________\n",
    "        # DENSE LAYERS\n",
    "        # Flatten output and feed it into dense layer:\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(n_classes, activation='softmax')]) # Output layer\n",
    "    \n",
    "    #------------------------------------\n",
    "    # COMPILING MODEL WITH APPROPRIATE LOSS AND OPTIMIZER\n",
    "\n",
    "    # Optimizer:\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "    # Loss function:\n",
    "    loss = keras.losses.CategoricalCrossentropy()\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca3594c-a2ff-4c54-a69c-7b82df7136c9",
   "metadata": {},
   "source": [
    "## 5-second segment melspectrogram input CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75e57c6-e300-4196-8879-3632f4e0293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_5_sec_melspectrogram(input_shape, n_classes=10, lr=0.0001): # There are 10 genres, so 10 classes\n",
    "    '''\n",
    "    Input parameters:\n",
    "    - `input_shape (tuple)`: Shape of input data\n",
    "    - `n_classes`: Number of output classes\n",
    "\n",
    "    Return values:\n",
    "    - `model`: CNN model\n",
    "    '''\n",
    "\n",
    "    # BUILD MODEL TOPOLOGY\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Input(input_shape),\n",
    "        keras.layers.Identity(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        #________________________\n",
    "        # CONVOLUTIONAL LAYERS\n",
    "        keras.layers.Conv2D(32, (2, 2), activation='relu'),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "\n",
    "        keras.layers.Conv2D(32, (2, 2), activation='relu'),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "\n",
    "        keras.layers.Conv2D(32, (2, 2), activation='relu'),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "\n",
    "        keras.layers.Conv2D(32, (2, 2), activation='relu'),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "\n",
    "        keras.layers.Conv2D(32, (2, 2), activation='relu'),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "\n",
    "        keras.layers.Conv2D(32, (2, 2), activation='relu'),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "\n",
    "        keras.layers.Conv2D(32, (2, 2), activation='relu'),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
    "        \n",
    "        keras.layers.Conv2D(32, (2, 2), activation='relu'),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        #________________________\n",
    "        # DENSE LAYERS\n",
    "        # Flatten output and feed it into dense layer:\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        keras.layers.Dense(n_classes, activation='softmax')]) # Output layer\n",
    "    \n",
    "    #------------------------------------\n",
    "    # COMPILING MODEL WITH APPROPRIATE LOSS AND OPTIMIZER\n",
    "\n",
    "    # Optimizer:\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "    # Loss function:\n",
    "    loss = keras.losses.CategoricalCrossentropy()\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c179b88d-9dde-444b-b943-011844b09d9f",
   "metadata": {},
   "source": [
    "# Saving and loading models\n",
    "**_Specifically model weights_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da50bfb-dfb2-4025-af1f-2d9e345bd438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, file_name):\n",
    "    W = {}\n",
    "    for i, weights in enumerate(model.get_weights()):\n",
    "        W[i] = weights\n",
    "    np.save(file_name, W)\n",
    "\n",
    "def load_model(model, file_name):\n",
    "    V = np.load(file_name, allow_pickle=True).tolist()\n",
    "    W = []\n",
    "    for i in range(len(V)):\n",
    "        W.append(V[i])\n",
    "    model.set_weights(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5e1e5c-fa5f-46d4-82f7-c6b68fd92ef6",
   "metadata": {},
   "source": [
    "# Reading and displaying model training logs and history\n",
    "(Logs made using `keras.callbacks.CSVLogger`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b29ee4-6462-493c-a38c-82c242fb17b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_logs(logs_file_path):\n",
    "    logs = []\n",
    "    f = open(logs_file_path, 'r')\n",
    "    file_contents = f.read().split('\\n')\n",
    "    \n",
    "    # 1st row is header, so skip:\n",
    "    headers = file_contents[0].split(',')\n",
    "    file_contents = file_contents[1:]\n",
    "    \n",
    "    # Adding each row as a list of floats:\n",
    "    for i in range(len(file_contents)):\n",
    "        if len(file_contents[i]) < 4: continue\n",
    "        logs.append([float(value) for value in file_contents[i].split(',')])\n",
    "    f.close()\n",
    "\n",
    "    # Storing logs as a dictionary for convenience:\n",
    "    logs = np.array(logs)\n",
    "    history = {}\n",
    "    for i, header in enumerate(headers):\n",
    "        history[header] = logs[:, i]\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d135a8-827b-4c58-b5cb-3b2fbaa11ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting model training history:\n",
    "def plot_model_history(history):\n",
    "    # Model accuracy across epochs:\n",
    "    plt.plot(history['accuracy'])\n",
    "    plt.plot(history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['training', 'validation'])\n",
    "    plt.show()\n",
    "\n",
    "    # Model loss across epochs:\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['training', 'validation'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bedb9e6-3498-470f-bf25-e9115fc365db",
   "metadata": {},
   "source": [
    "# Predicting from trained model\n",
    "**NOTE**: We assume the input is one or more MFCC arrays or melspectrograms for one or more appropriately-sized segments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b6b273-872e-4ecb-8d36-1506e06c2664",
   "metadata": {},
   "source": [
    "### Important constants and variables\n",
    "\n",
    "- List of all genres\n",
    "- Genre-to-integer maps and inverse maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679e3e21-b9d7-4983-beda-f6b31809cff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
    "genre_to_integer_map = {}\n",
    "integer_to_genre_map = {}\n",
    "    \n",
    "# Genre-to-integer:\n",
    "for i, genre in enumerate(genres):\n",
    "    genre_to_integer_map[genre] = i\n",
    "\n",
    "# Integer-to-genre:\n",
    "for i, genre in enumerate(genres):\n",
    "    integer_to_genre_map[i] = genre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2931d8-34fc-4870-b87c-28e208fb8da0",
   "metadata": {},
   "source": [
    "### Prediction processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be4590b-46c8-4310-896d-083f9282848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get predictions (as genre names) per segment (returns a list of predictions):\n",
    "def get_predictions_per_segment(model, melspectrograms):    \n",
    "    # If only a single segment's melspectrogram is given, add dimensions:\n",
    "    if len(melspectrograms.shape) == 2:\n",
    "        melspectrograms = np.expand_dims(melspectrograms, axis=0)\n",
    "        \n",
    "    # Getting raw predictions:\n",
    "    predictions = np.argmax(model(melspectrograms), axis=1)\n",
    "    # NOTE: The index of the maximum predicted class = Target integer of the predicted class\n",
    "    \n",
    "    # Getting cooked predictions:\n",
    "    predictions = [integer_to_genre_map[p] for p in predictions]\n",
    "\n",
    "    return predictions\n",
    "\n",
    "#================================================\n",
    "# Function to get the proportion of each predicted class from the overall predictions:\n",
    "def get_predictions_overall(model, melspectrograms):\n",
    "    predictions = get_predictions_per_segment(model, melspectrograms)\n",
    "\n",
    "    # Getting counts for each prediction:\n",
    "    predictions_tracker = {}\n",
    "    for p in predictions:\n",
    "        try:\n",
    "            predictions_tracker[p] += 1\n",
    "        except:\n",
    "            predictions_tracker[p] = 1\n",
    "\n",
    "    # Getting as proportions:\n",
    "    total = float(len(predictions))\n",
    "    for key in predictions_tracker:\n",
    "        predictions_tracker[key] = predictions_tracker[key] / total\n",
    "\n",
    "    return predictions_tracker\n",
    "\n",
    "#================================================\n",
    "# Function to display and return the results of `get_predictions_overall`:\n",
    "def get_predictions_summary(model, melspectrograms, return_value=True):\n",
    "    predictions_tracker = get_predictions_overall(model, melspectrograms)\n",
    "    for key in predictions_tracker:\n",
    "        print(f'Proportion of total predictions for class \"{key}\" = {predictions_tracker[key]}')\n",
    "    \n",
    "    if return_value:\n",
    "        return predictions_tracker"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
